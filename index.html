<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/night.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
	<section>
	    <h5>Bates Digital Music Symposium 2018</h5>
	    <br>
	  <h3>socketMusic: wireless (2015)</h3>
	  <h4>for improvised percussion, electronic sound, and mobile devices</h4>
	  <h3>by Derek Kwan</h3>
	  <h7>http(s)://derekxkwan.com</h7>
	  <h7> https://derekxkwan.github.io/smwireless-slides/</h7>
	</section>
	<section>
	    <h3>Outline</h3>
	    <ul>
		<li>general info (form/compositional details/aesthetics)</li>
		<li>breakdown tech stack</li>
		<ul>
		    <li>use of chance procedures as improv aid</li>
		    <li>technical considerations</li>
		</ul>
		<li>further explorations</li>
	    </ul>
	</section>
	<section>
	    <section><h2>Background Info</h2></section>
	    <section>
		<h3>Instrumentation</h3>
		<ul>
		    <li>(improvised) percussion: snare drum (+ found metal), hi hat</li>
		    <li>electronics: processed samples, processed percussion, synthesized sound</li>
		    <li>mobile devices: sounds triggered by web server</li>
		</ul>
	    </section>
	    <section>
		<h3>Form</h3>
		<ul>
		    <li>three large sections with contrasting textures + improv. styles</li>
		    <ul>
			<li>drone + hiss / modem</li>
			<ul>
			    <li>in part inspired by Contact opening scene (zoomout)</li>
			    <li>textural improv on SD/HH with dreadlock brushes</li>
			    <li>cell phones accumulate in radio samples / filtered noise bursts</li>
			    <li>chopped/reversed input recordings</li>
			</ul>
		    </ul>
		</ul>
		
	    </section>
	    <section>
		<h3>Form cont.</h3>
		<ul>
		    <li>(three large sections cont.)</li>
		    <ul>
			<li>radio + static</li>
			<ul>
			    <li>based around 60 bpm pulse</li>
			    <ul>
				<li>delayed beeps + second roving beep at 59.7015 bpm</li>
			    </ul>
			    <li>hihat rolls synced with radio/static</li>
			    <ul>
				<li>multi-tap delay with each delay randomly panned</li>
			    </ul>
			    <li>cell phones imitate modem sound from end of sec 1 (enter sequentially)</li>
			</ul>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Form cont.</h3>
		<ul>
		    <li>(three large sections cont.)</li>
		    <ul>
			<li>telegraph</li>
			<ul>
			    <li>hiss + clicks on speakers</li>
			    <li>sea of morse code pulses (cell phones) imitated on HH/metal on SD</li>
			    <li>ends with brown noise swell</li>
			</ul>
			<li>Note: all durations and subevents determined at runtime in Pure Data</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Background</h3>
		<ul>
		    <li>working at Stony Brook's Teaching Learning Lab (media lab) - wanted to apply computer programming to doctoral recital</li>
		    <li>inspiration - Steven Schick premiere - Lei Liang's <i>Trans</i> (2014) (Miller Theater, Columbia)</li>
		    <ul>
			<li>distributed stones to audience, signaled when to strike from stage</li>
		    </ul>
		    <li>wanted an inexpensive way to do multichannel audio</li>
		</ul>
	    </section>
	    <section>
		<h3>Aesthetics</h3>
		<ul>
		    <li>wireless - in content and medium</li>
		    <li>breaking cultural (concert hall) norms</li>
		    <ul>
			<li>performer/composer/audience relationship/balance of power</li>
			<ul>
			    <li>improvisation, chance procedures on server/patch/mobile devices</li>
			    <li>audience participation (active vs passive)</li>
			</ul>
			<li>stage/hall invisible wall</li>
			<li>performer/stage as focus of attention - audio/visuals on cell phone</li>
			<li>not silencing cell phones</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Aesthetics cont.</h3>
		<ul>
		    <li>spatialization</li>
		    <ul>
			<li>massively multichannel</li>
			<li>immersivity (sound sources from audience)</li>
			<li>chance-based location and volume (depends on audience)</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Aesthetics cont.</h3>
		<ul>
		    <li>randomization</li>
		    <ul>
			<li>hands-free organicity (division of duties)</li>
			<li>computer as performer (living piece)</li>
			<li>unpredictability (vs fixed-media/performer+tape)</li>
			<li>"fuzzy"/aleatoric composing</li>
			<ul>
			    <li>composing in general outlines/proportions, leaving computer to fill out details</li>
			    <li>specifying rates of triggering, chances of triggering, ranges of parameters</li>
			</ul>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Sounds</h3>
		<ul>
		    <li>majority of sounds reference wireless technology (samples, synthesis)</li>
		    <ul>
			<li>wireless telegraph (radio waves) - Guglielmo Marconi (patented 1896)</li>
			<li>first public radio broadcast - Lee De Forest/Metropolitan Opera (12/3/1910)</li>
			<ul>
			    <li>Enrico Caruso as Canio - I Pagliacci (Leoncavallo)</li>
			    <li>Riccardo Martin as Turridu - Cavalieria Rusticana (Mascagni)</li>
			</ul>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Sounds cont.</h3>
		<ul>
		    <li>1200 baud modem (not quite wireless, but evokes the WiFi-enabled nature of the piece)</li>
		    <li>other misc sounds (radio static, fake talk radio)</li>
		</ul>
	
	    </section>
	</section>
	<section>
	    <section><h2>Technical Details</h2></section>
	    <section>
		<h3>Software Tech Stack</h3>
		<ul>
		    <li>Pure Data - brains</li>
		    <ul>
			<li>sound for on-stage speakers, scheduling, cues</li>
		    </ul>
		    <li>Node.js (Macchiato/Clojurescript) - messasge forwarder</li>
		    <ul>
			<li>host web page</li>
			<li>OSC communication with Pure Data</li>
			<li>WebSocket communication with individual clients (socket.io)</li>
			<ul>
			    <li>triggered events from Pd via OSC</li>
			</ul>
		    </ul>
		</ul>
		</section>
		<section>
		    <h3>Software Tech Stack cont.</h3>
		    <ul>
			<li>HTML/CSS/JS(CLJS) - message implementer</li>
			<ul>
			    <li>client-facing view</li>
			    <li>React/Reagent/JS - reactive visuals/info display</li>
			    <li>Web Audio API/Tone.js - synths, samples</li>
			    <li>Websocket communication with server via socket.io</li>
			</ul>
		    </ul>
		</section>
		<section>
		    <h3>Hardware Tech Stack</h3>
		    <ul>
			<li>laptop</li>
			<li>audio interface (+ mics)</li>
			<li>wireless router</li>
		    </ul>
		</section>
	</section>
	<section>
	    <section>
		<h2>Pure Data</h2>
	    </section>
	    <section>
		<div class="card-img" height="80%" width="80%">
		    <img src="res/smw-pdpatch.png" width="auto" max-height="50%"/>
		</div>
	    </section>
	    <section>
		<h3>Jobs</h3>
		<ul>
		    <li>audio for on-stage speakers</li>
		    <ul>
			<li>live input recording (attack-triggered at max rate of 20s) / processing (rev./chopped, delays, FFT bin mag. thresholding)</li>
			<li>samples + synthesis</li>
		    </ul>
		    <li>user interface (controls, clocks, cues)</li>
		    <ul>
			<li>clocks for overall piece, current section, current section duration, next event timing</li>
			<li>sec. 2 - cues for roll entrances 8th note before start and finish</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Jobs cont.</h3>
		<ul>
		    <li>scheduling and triggering</li>
		    <ul>
			<li>determine structure of piece (3 major sections)</li>
		    </ul>
		    <ul>
			<li>communication with node.js server (OSC)</li>
			<ul>
			    <li>retrieve client list (base64)</li>
			    <li>direct server to trigger events (WebSockets)</li>
			</ul>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Chance Operations</h3>
		<ul>
		    <li>overall section durations</li>
		    <ul>
			<li>randomly chosen within ranges to add up to at least seven minutes</li>
		    </ul>
		    <li>timings of events/subsections</li>
		    <ul>
			<li>approx. times with given ranges (smw-nextsubsec 50 7 -> 50 seconds in given section +/- 7)</li>
			<li>perc. part cued as well! (sec. 2)</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Chance Operations cont.</h3>
		<ul>
		    <li>specific contents of events</li>
		    <ul>
			<li>random selection of given range of clients</li>
			<li>random selection and playback location of sound files (sec. 2)</li>
			<li>randomization of parameters of synthesized sounds (sec.1 drone)</li>
			<li>random triggering (and selection of params within given ranges) of samples</li>
			<li>randomization of delay lines (section 2)</li>
		    </ul>
		    <li>all based around abstractions of [random] object (LCG)</li>
		</ul>
	    </section>
	</section>
	<section>
	    <section>
		<h2>Node.js server</h2>
	    </section>
	    <section>
		<h3>Jobs</h3>
		<ul>
		    <li>serve web page for clients</li>
		    <li>keep track of indiv. connections via WebSockets (socket.io)</li>
		    <ul>
			<li>trigger events on all devices (broadcast)</li>
			<li>trigger events on a specific device (emit)</li>
		    </ul>
		    <li>communicate with Pure Data (OSC)</li>
		    <ul>
			<li>provide list of connections (base64)</li>
			<li>forward triggers from Pd to clients</li>
		    </ul>
		</ul>
	    </section>
	</section>
	<section>
	    <section>
		<h2>Client (HTML/CSS/JS via CLJS)</h2>
	    </section>
	    <section>
		<div class="card-img" height="80%" width="80%">
		    <img src="res/smw-client.png" width="auto" max-height="50%"/>
		</div>
	    </section>
	    <section>
		<h3>Jobs</h3>
		<ul>
		    <li>client-facing interface loaded on devices</li>
		    <ul>
			<li>CSS, JS for dynamic background, React (Reagent) for dynamic text</li>
		    </ul>
		    <li>sound synthesis/playback (Web Audio API / Tone.js)</li>
		    <ul>
			<li>triggered by Node webserver (with visual feedback)</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Chance Operations</h3>
		<ul>
		    <li>all sequences generated client-side (audio.cljs)</li>
		    <ul>
			<li>chopped samples (sec. 1), filtered noise (sec. 1), telegraph beeps (sec. 3)</li>
			<li>freq / dur / Q / sample location / amp. / etc. </li>
		    </ul>
		    <li>start times of sequences (client.cljs)</li>
		    <ul>
			<li>flags from OSC for immed. start / delayed</li>
		    </ul>
		    <li>other sound parameters</li>
		    <ul>
			<li>base freq. for modem synths (clicks/whine)</li>
			<li>speed of modem clicks (subdivisions of 4s)</li>
			<li>freq of sine osc. for telegraph</li>
		    </ul>
		</ul>
	    </section>
	</section>
	<section>
	    <section>
		<h2>Technical Discussion</h2>
	    </section>
	    <section>
		<h3>Technical Notes</h3>
		<ul>
		    <li>why browser and not native?</li>
		    <ul>
			<li>easily (comparatively) cross-platform</li>
			<li>no need to download additional software</li>
			<li>server/client</li>
			<li>cons</li>
			<ul>
			    <li>data payload size</li>
			    <li>limited to browser capabilities/non-native</li>
			</ul>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h3>Technical Considerations</h3>
		<ul>
		    <li>accessing hosted web site?</li>
		    <ul>
			<li>static IP (easy, /etc/network/interfaces on *nix) </li>
			<li>router and DNS server?</li>
			<ul>
			    <li>OpenWrt (DNS)</li>
			    <li>Dynamic DNS (host on computer with bind?)</li>
			</ul>
			<li>qr-code direct to static ip</li>
		    </ul>
		    <li>port number (port 80/custom port)</li>
		    <ul>
			<li>port 80 (Web): setcap 'cap_net_bind_service+3p' /usr/bin/nodejs</li>
		    </ul>
		</ul>
	    </section>
	    <section>
		<h7>qr-code for static-ip addr. w/ page served on 8080</h7>
		<div class="card-img" height="80%" width="80%">
		    <img src="res/qr-large.png" width="auto" max-height="50%"/>
		</div>
		<h7>gen. w/  Racket Simple-Qr library (Chen Xiao)</h7>
	    </section>
	    <section>
		<h3>Technical Considerations cont.</h3>
		<ul>
		    <li>Apple/iOS - need user interaction to start audio context</li>
		    <li>latencies from WiFi (rhythmic/timing accuracy)</li>
		    <li>auto-screen lock without interaction</li>
		    <ul>
			<li>NoSleep.js - https://github.com/richtr/NoSleep.js</li>
		    </ul>
		</ul>
	    </section>
	</section>
	<section>
	    <h3>Further Exploration</h3>
	    <ul>
		<li>not only for concert hall (installations)</li>
		<li>streaming live sound - maybe Icecast/WebRTC/recording-loading sounds?</li>
		<li>more sophisticated visualizations</li>
		<ul>
		    <li>P5.js, Canvas, Three.js, Quil, AR.js...</li>
		</ul>
		<li>greater user interactivity</li>
		<ul>
		    <li>many options for input (text, accelerometers, sensors, GUI)</li>
		    <li>user control of sound, user supply of sound</li>
		    <li>interactions: user-server, user-user</li>
		    <ul>
			<li>user data</li>
		    </ul>
		</ul>
	    </ul>
	</section>
	<section>
	    <section>
		<h3>Biblography</h3>
		<ul>
		    <li>
			"[Met Performance] CID:49210." MetOpera Database: The Metropolitan Opera Archives, Metropolitan Opera Association, archives.metoperafamily.org/archives/scripts/cgiip.exe/WService=BibSpeed/fullcit.w?xCID=49210&limit=2500&xBranch=ALL&xsdate=&xedate=&theterm=1910-11&x=0&xhomepath=&xhome=. Archive of December 3, 1910 Matinee Program Information</li>
		</ul>
	    </section>
	    <section>
		<h3>Bibliography cont.</h3>
		<ul>
		    <li>
			Kane, Joseph Nathan. Famous First Facts. The H.W. Wilson Company, 1964.</li>
		    <li>Fantel, Hans. "Sound; Out of De Forest And Onto The Air Came Music." The New York Times, 14 Jan. 1990, p. 002030, www.nytimes.com/1990/01/14/arts/sound-out-of-de-forest-and-onto-the-air-came-music.html.</li>
		</ul>

	    </section>
	    <section>
		<h3>Bibliography cont.</h3>
		<ul>
		    <li>
			Sims, Michael. "Cavalleria Rusticana and I Pagliacci Crimes of Passion." Cavalleria Rusticana and I Pagliacci, www.concertoperaboston.org/cavalleria.html.</li>
		    <li>Guglielmo Marconi - Biographical. NobelPrize.org. Nobel Media AB 2018. Sun. 14 Oct 2018. <https://www.nobelprize.org/prizes/physics/1909/marconi/biographical/> </li>
		</ul>
	    </section>
	</section>
      </div>
    </div>
    <script src="js/reveal.js"></script>
    <script>
      Reveal.initialize();
    </script>
  </body>
</html>
    
      
